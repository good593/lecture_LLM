{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e0fad7b",
   "metadata": {},
   "source": [
    "# DeepSpeed í•™ìŠµ ê°€ì´ë“œ (ê°„ì†Œí™”)\n",
    "\n",
    "## DeepSpeedë€ ë¬´ì—‡ì¸ê°€?\n",
    "\n",
    "### 1. DeepSpeedì˜ ê°œë…\n",
    "DeepSpeedëŠ” Microsoftì—ì„œ ê°œë°œí•œ ë”¥ëŸ¬ë‹ ìµœì í™” ë¼ì´ë¸ŒëŸ¬ë¦¬ì…ë‹ˆë‹¤. ëŒ€ê·œëª¨ ëª¨ë¸ì„ íš¨ìœ¨ì ìœ¼ë¡œ í•™ìŠµì‹œí‚¤ê¸° ìœ„í•´ ë§Œë“¤ì–´ì¡Œìœ¼ë©°, íŠ¹íˆ LLM(Large Language Model) í•™ìŠµì— ë§¤ìš° ìœ ìš©í•©ë‹ˆë‹¤.\n",
    "\n",
    "### 2. ì™œ DeepSpeedê°€ í•„ìš”í•œê°€?\n",
    "\n",
    "#### ë¬¸ì œ ìƒí™©\n",
    "- í˜„ëŒ€ì˜ LLMì€ ìˆ˜ì‹­ì–µ ê°œì˜ íŒŒë¼ë¯¸í„°ë¥¼ ê°€ì§‘ë‹ˆë‹¤\n",
    "- ì´ëŸ° í° ëª¨ë¸ì„ í•™ìŠµí•˜ë ¤ë©´ ì—„ì²­ë‚œ GPU ë©”ëª¨ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤\n",
    "- ì¼ë°˜ì ì¸ GPU í•˜ë‚˜ë¡œëŠ” ë©”ëª¨ë¦¬ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤\n",
    "- í•™ìŠµ ì†ë„ê°€ ë§¤ìš° ëŠë¦½ë‹ˆë‹¤\n",
    "\n",
    "#### DeepSpeedì˜ í•´ê²°ì±…\n",
    "DeepSpeedëŠ” ë‹¤ìŒê³¼ ê°™ì€ ê¸°ìˆ ë“¤ì„ í†µí•´ ì´ ë¬¸ì œë“¤ì„ í•´ê²°í•©ë‹ˆë‹¤:\n",
    "\n",
    "1. **ë©”ëª¨ë¦¬ ìµœì í™”**: ëª¨ë¸ì˜ ë‹¤ë¥¸ ë¶€ë¶„ë“¤ì„ ì—¬ëŸ¬ GPUì— ë‚˜ëˆ„ì–´ ì €ì¥\n",
    "2. **ê³„ì‚° ìµœì í™”**: ë³‘ë ¬ ì²˜ë¦¬ë¥¼ í†µí•´ í•™ìŠµ ì†ë„ í–¥ìƒ\n",
    "3. **í†µì‹  ìµœì í™”**: GPU ê°„ ë°ì´í„° ì „ì†¡ì„ íš¨ìœ¨í™”\n",
    "\n",
    "### 3. DeepSpeedì˜ ì£¼ìš” ê¸°ëŠ¥ë“¤\n",
    "\n",
    "#### ZeRO (Zero Redundancy Optimizer)\n",
    "- **ZeRO Stage 1**: ì˜µí‹°ë§ˆì´ì € ìƒíƒœë¥¼ ì—¬ëŸ¬ GPUì— ë¶„ì‚°\n",
    "- **ZeRO Stage 2**: ê·¸ë˜ë””ì–¸íŠ¸ë„ ì—¬ëŸ¬ GPUì— ë¶„ì‚°\n",
    "- **ZeRO Stage 3**: ëª¨ë¸ íŒŒë¼ë¯¸í„°ê¹Œì§€ ì—¬ëŸ¬ GPUì— ë¶„ì‚°\n",
    "\n",
    "#### 3D Parallelism\n",
    "- **ë°ì´í„° ë³‘ë ¬**: ê°™ì€ ëª¨ë¸ì„ ì—¬ëŸ¬ GPUì—ì„œ ë‹¤ë¥¸ ë°ì´í„°ë¡œ í•™ìŠµ\n",
    "- **ëª¨ë¸ ë³‘ë ¬**: ëª¨ë¸ ìì²´ë¥¼ ì—¬ëŸ¬ GPUì— ë‚˜ëˆ„ì–´ ë°°ì¹˜\n",
    "- **íŒŒì´í”„ë¼ì¸ ë³‘ë ¬**: ëª¨ë¸ì˜ ë ˆì´ì–´ë“¤ì„ ìˆœì°¨ì ìœ¼ë¡œ ì—¬ëŸ¬ GPUì— ë°°ì¹˜\n",
    "\n",
    "### 4. DeepSpeed vs ì¼ë°˜ í•™ìŠµ ë¹„êµ\n",
    "\n",
    "| êµ¬ë¶„ | ì¼ë°˜ í•™ìŠµ | DeepSpeed |\n",
    "|------|-----------|-----------| \n",
    "| ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ | ë†’ìŒ | ë‚®ìŒ (ìµœëŒ€ 80% ì ˆì•½) |\n",
    "| í•™ìŠµ ì†ë„ | ëŠë¦¼ | ë¹ ë¦„ (ì—¬ëŸ¬ GPU í™œìš©) |\n",
    "| ëª¨ë¸ í¬ê¸° ì œí•œ | GPU ë©”ëª¨ë¦¬ì— ì˜ì¡´ | í›¨ì”¬ í° ëª¨ë¸ ê°€ëŠ¥ |\n",
    "| ì„¤ì • ë³µì¡ë„ | ê°„ë‹¨ | ì´ˆê¸° ì„¤ì • í•„ìš” |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce42c5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "libopenmpi-dev is already the newest version (4.1.2-2ubuntu1).\n",
      "openmpi-bin is already the newest version (4.1.2-2ubuntu1).\n",
      "openmpi-common is already the newest version (4.1.2-2ubuntu1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 92 not upgraded.\n",
      "Requirement already satisfied: deepspeed in /usr/local/lib/python3.11/dist-packages (0.17.5)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.56.0)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (4.0.0)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.10.1)\n",
      "Requirement already satisfied: mpi4py in /usr/local/lib/python3.11/dist-packages (4.1.0)\n",
      "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from deepspeed) (0.8.1)\n",
      "Requirement already satisfied: hjson in /usr/local/lib/python3.11/dist-packages (from deepspeed) (3.1.0)\n",
      "Requirement already satisfied: msgpack in /usr/local/lib/python3.11/dist-packages (from deepspeed) (1.1.1)\n",
      "Requirement already satisfied: ninja in /usr/local/lib/python3.11/dist-packages (from deepspeed) (1.13.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from deepspeed) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from deepspeed) (24.2)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from deepspeed) (7.0.0)\n",
      "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from deepspeed) (9.0.0)\n",
      "Requirement already satisfied: pydantic>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from deepspeed) (2.11.7)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from deepspeed) (2.8.0.dev20250319+cu128)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from deepspeed) (4.67.1)\n",
      "Requirement already satisfied: nvidia-ml-py in /usr/local/lib/python3.11/dist-packages (from deepspeed) (13.580.65)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.34.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2025.9.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.22.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.3.2)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2024.10.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.9)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0.0->deepspeed) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0.0->deepspeed) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0.0->deepspeed) (0.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (3.1.4)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.61 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.57 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.57 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.8.0.87 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (9.8.0.87)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.3.14 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (12.8.3.14)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.41 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (11.3.3.41)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.55 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (10.3.9.55)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.2.55 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (11.7.2.55)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.7.53 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (12.5.7.53)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.25.1 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (2.25.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.55 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (12.8.55)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.61 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.0.11 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (1.13.0.11)\n",
      "Requirement already satisfied: pytorch-triton==3.3.0+git96316ce5 in /usr/local/lib/python3.11/dist-packages (from torch->deepspeed) (3.3.0+git96316ce5)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-triton==3.3.0+git96316ce5->torch->deepspeed) (77.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch->deepspeed) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->deepspeed) (2.1.5)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "/usr/bin/mpirun\n",
      "mpirun (Open MPI) 4.1.2\n",
      "\n",
      "Report bugs to http://www.open-mpi.org/community/help/\n",
      "ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\n"
     ]
    }
   ],
   "source": [
    "# 1ë‹¨ê³„: í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
    "# MPI ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ (DeepSpeed ì˜¤ë¥˜ í•´ê²°ìš©)\n",
    "!apt-get update -qq\n",
    "!apt-get install -y openmpi-bin openmpi-common libopenmpi-dev\n",
    "\n",
    "# Python íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "!pip install deepspeed transformers datasets accelerate mpi4py\n",
    "\n",
    "# MPI ì„¤ì¹˜ í™•ì¸\n",
    "!which mpirun\n",
    "!mpirun --version\n",
    "\n",
    "print(\"ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c92d3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ëª¨ë“  ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„±ê³µì ìœ¼ë¡œ ì„í¬íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤!\n",
      "PyTorch ë²„ì „: 2.8.0.dev20250319+cu128\n",
      "CUDA ì‚¬ìš© ê°€ëŠ¥: True\n"
     ]
    }
   ],
   "source": [
    "# 2ë‹¨ê³„: ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForCausalLM, \n",
    "    TrainingArguments, \n",
    "    Trainer,\n",
    "    DataCollatorForLanguageModeling\n",
    ")\n",
    "from datasets import Dataset\n",
    "import json\n",
    "import os\n",
    "\n",
    "print(\"ëª¨ë“  ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„±ê³µì ìœ¼ë¡œ ì„í¬íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "print(f\"PyTorch ë²„ì „: {torch.__version__}\")\n",
    "print(f\"CUDA ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53f47317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í•œêµ­ì–´ ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e245a0c7ce544ab3af3dbfca722b5482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ëª¨ë¸ì´ GPUë¡œ ì´ë™: cuda:0\n",
      "í•œêµ­ì–´ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!\n",
      "ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜: 1,331,810,304\n"
     ]
    }
   ],
   "source": [
    "# 3ë‹¨ê³„: í•œêµ­ì–´ ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¡œë“œ (device_map ì—†ì´)\n",
    "print(\"í•œêµ­ì–´ ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤...\")\n",
    "\n",
    "# í•œêµ­ì–´ íŠ¹í™” ëª¨ë¸ ì„ íƒ\n",
    "model_name = \"EleutherAI/polyglot-ko-1.3b\"  # 1.3B íŒŒë¼ë¯¸í„°\n",
    "\n",
    "try:\n",
    "    # í† í¬ë‚˜ì´ì € ë¡œë“œ\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "    # ëª¨ë¸ ë¡œë“œ (device_map ì‚¬ìš© ì•ˆí•¨ - DeepSpeed í˜¸í™˜)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        dtype=torch.float16,\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "    \n",
    "    # GPUë¡œ ì´ë™\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "        print(f\"ëª¨ë¸ì´ GPUë¡œ ì´ë™: {next(model.parameters()).device}\")\n",
    "    \n",
    "    print(\"í•œêµ­ì–´ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!\")\n",
    "    print(f\"ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜: {model.num_parameters():,}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"í•œêµ­ì–´ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "    print(\"GPT-2 ëª¨ë¸ì„ ëŒ€ì•ˆìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤...\")\n",
    "    \n",
    "    model_name = \"gpt2\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "        \n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        model_name,\n",
    "        dtype=torch.float16\n",
    "    )\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "    \n",
    "    print(\"GPT-2 ëª¨ë¸ë¡œ ì„¤ì • ì™„ë£Œ!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e58d90e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì´ í•œêµ­ì–´ í•™ìŠµ í…ìŠ¤íŠ¸ ìˆ˜: 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b42b0266edf645299aba6347008dbf4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í•™ìŠµ ë°ì´í„°ì…‹ í¬ê¸°: 8\n"
     ]
    }
   ],
   "source": [
    "# 4ë‹¨ê³„: í•œêµ­ì–´ í•™ìŠµ ë°ì´í„° ì¤€ë¹„\n",
    "korean_texts = [\n",
    "    \"ì¸ê³µì§€ëŠ¥ì€ ìš°ë¦¬ ì¼ìƒì„ ë³€í™”ì‹œí‚¤ëŠ” í˜ì‹ ì ì¸ ê¸°ìˆ ì…ë‹ˆë‹¤. ìŠ¤ë§ˆíŠ¸í°ì˜ ìŒì„±ì¸ì‹ë¶€í„° ììœ¨ì£¼í–‰ì°¨ê¹Œì§€ ë‹¤ì–‘í•œ ë¶„ì•¼ì—ì„œ í™œìš©ë˜ê³  ìˆìŠµë‹ˆë‹¤.\",\n",
    "    \"ë”¥ëŸ¬ë‹ì€ ì¸ê°„ì˜ ë‡Œ êµ¬ì¡°ë¥¼ ëª¨ë°©í•œ ì‹ ê²½ë§ ê¸°ìˆ ë¡œ, ë³µì¡í•œ íŒ¨í„´ ì¸ì‹ê³¼ í•™ìŠµì´ ê°€ëŠ¥í•©ë‹ˆë‹¤. ì´ë¯¸ì§€ ì¸ì‹, ìì—°ì–´ ì²˜ë¦¬ ë“±ì—ì„œ ë†€ë¼ìš´ ì„±ê³¼ë¥¼ ë³´ì—¬ì£¼ê³  ìˆìŠµë‹ˆë‹¤.\",\n",
    "    \"ìì—°ì–´ ì²˜ë¦¬ëŠ” ì»´í“¨í„°ê°€ ì¸ê°„ì˜ ì–¸ì–´ë¥¼ ì´í•´í•˜ê³  ìƒì„±í•  ìˆ˜ ìˆê²Œ í•˜ëŠ” ê¸°ìˆ ì…ë‹ˆë‹¤. ë²ˆì—­, ìš”ì•½, ì§ˆë¬¸ë‹µë³€ ë“± ë‹¤ì–‘í•œ ì–¸ì–´ ì‘ì—…ì„ ìë™í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\",\n",
    "    \"íŠ¸ëœìŠ¤í¬ë¨¸ ì•„í‚¤í…ì²˜ëŠ” í˜„ëŒ€ ìì—°ì–´ ì²˜ë¦¬ì˜ í•µì‹¬ ê¸°ìˆ ì…ë‹ˆë‹¤. ì–´í…ì…˜ ë©”ì»¤ë‹ˆì¦˜ì„ í†µí•´ ë¬¸ë§¥ ì •ë³´ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì²˜ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\",\n",
    "    \"íŒŒì¸íŠœë‹ì€ ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ì„ íŠ¹ì • ì‘ì—…ì— ë§ê²Œ ì¡°ì •í•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤. ì ì€ ë°ì´í„°ë¡œë„ ë†’ì€ ì„±ëŠ¥ì„ ë‹¬ì„±í•  ìˆ˜ ìˆëŠ” íš¨ìœ¨ì ì¸ ë°©ë²•ì…ë‹ˆë‹¤.\",\n",
    "    \"í•œêµ­ì˜ ì‚¬ê³„ì ˆì€ ê°ê° ë…íŠ¹í•œ ì•„ë¦„ë‹¤ì›€ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. ë´„ì˜ ë²šê½ƒ, ì—¬ë¦„ì˜ ë…¹ìŒ, ê°€ì„ì˜ ë‹¨í’, ê²¨ìš¸ì˜ ì„¤ê²½ì´ ëª¨ë‘ ë§¤ë ¥ì ì…ë‹ˆë‹¤.\",\n",
    "    \"í•œêµ­ ìŒì‹ì€ ë°œíš¨ ë¬¸í™”ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œ ê±´ê°•í•œ ì‹ë¬¸í™”ë¥¼ ìë‘í•©ë‹ˆë‹¤. ê¹€ì¹˜, ëœì¥, ê³ ì¶”ì¥ ë“±ì€ ì„¸ê³„ì ìœ¼ë¡œ ì¸ì •ë°›ëŠ” ë°œíš¨ì‹í’ˆì…ë‹ˆë‹¤.\",\n",
    "    \"K-íŒê³¼ K-ë“œë¼ë§ˆëŠ” í•œë¥˜ì˜ ì¤‘ì‹¬ìœ¼ë¡œ ì „ ì„¸ê³„ì— í•œêµ­ ë¬¸í™”ë¥¼ ì•Œë¦¬ê³  ìˆìŠµë‹ˆë‹¤. ìŒì•…ê³¼ ì˜ìƒ ì½˜í…ì¸ ì˜ í’ˆì§ˆì´ ë§¤ìš° ë†’ìŠµë‹ˆë‹¤.\"\n",
    "]\n",
    "\n",
    "print(f\"ì´ í•œêµ­ì–´ í•™ìŠµ í…ìŠ¤íŠ¸ ìˆ˜: {len(korean_texts)}\")\n",
    "\n",
    "# í…ìŠ¤íŠ¸ í† í°í™”\n",
    "def tokenize_function(examples):\n",
    "    tokenized = tokenizer(\n",
    "        examples[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=128,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    tokenized[\"labels\"] = tokenized[\"input_ids\"].clone()\n",
    "    return tokenized\n",
    "\n",
    "# ë°ì´í„°ì…‹ ìƒì„±\n",
    "train_dataset = Dataset.from_dict({\"text\": korean_texts})\n",
    "train_dataset = train_dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=[\"text\"]\n",
    ")\n",
    "\n",
    "print(f\"í•™ìŠµ ë°ì´í„°ì…‹ í¬ê¸°: {len(train_dataset)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29b19a99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ê°„ë‹¨í•œ ì„¤ì •ìœ¼ë¡œ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤...\n",
      "==================================================\n",
      "[2025-09-03 10:58:13,696] [INFO] [real_accelerator.py:260:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/bin/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "/usr/bin/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-09-03 10:58:15,335] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 2}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í•™ìŠµ ì „ GPU ë©”ëª¨ë¦¬: 2541.23 MB\n",
      "í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 00:22, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.074900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "âœ… í•™ìŠµì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\n",
      "í•™ìŠµ í›„ GPU ë©”ëª¨ë¦¬: 7640.07 MB\n"
     ]
    }
   ],
   "source": [
    "# 5ë‹¨ê³„: ê°„ë‹¨í•œ í•™ìŠµ ì‹¤í–‰ (DeepSpeed ëŒ€ì‹  ì¼ë°˜ Trainer ì‚¬ìš©)\n",
    "print(\"ê°„ë‹¨í•œ ì„¤ì •ìœ¼ë¡œ í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# ê°„ë‹¨í•œ TrainingArguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./simple_output\",\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=2,\n",
    "    save_steps=10,\n",
    "    logging_steps=1,\n",
    "    learning_rate=5e-5,\n",
    "    warmup_steps=1,\n",
    "    weight_decay=0.01,\n",
    "    fp16=True,\n",
    "    dataloader_num_workers=0,\n",
    "    remove_unused_columns=False,\n",
    "    report_to=None,\n",
    ")\n",
    "\n",
    "# ë°ì´í„° ì½œë ˆì´í„°\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False,\n",
    ")\n",
    "\n",
    "# Trainer ìƒì„±\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    data_collator=data_collator,\n",
    "    processing_class=tokenizer,\n",
    ")\n",
    "\n",
    "# í•™ìŠµ ì „ ë©”ëª¨ë¦¬ í™•ì¸\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"í•™ìŠµ ì „ GPU ë©”ëª¨ë¦¬: {torch.cuda.memory_allocated() / 1024**2:.2f} MB\")\n",
    "\n",
    "# í•™ìŠµ ì‹¤í–‰\n",
    "try:\n",
    "    print(\"í•™ìŠµì„ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "    trainer.train()\n",
    "    \n",
    "    print(\"=\" * 50)\n",
    "    print(\"âœ… í•™ìŠµì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"í•™ìŠµ í›„ GPU ë©”ëª¨ë¦¬: {torch.cuda.memory_allocated() / 1024**2:.2f} MB\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ í•™ìŠµ ì‹¤íŒ¨: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "317ade16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í•™ìŠµëœ ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤...\n",
      "==================================================\n",
      "\n",
      "í…ŒìŠ¤íŠ¸ 1: 'ì¸ê³µì§€ëŠ¥ì€'\n",
      "ìƒì„± ê²°ê³¼: ì¸ê³µì§€ëŠ¥ì€ ë¯¸ë˜ì˜ ì¸ë¥˜ë¥¼ ì–´ë–»ê²Œ ë°”ê¿€ ê²ƒì¸ê°€? - 1ë¶€ : 4ì°¨ ì‚°ì—…í˜ëª…ì˜ ì‹œì‘, ì¸ê³µì§€ëŠ¥ì˜ ë¯¸ë˜ - 2ë¶€: ì¸ê³µì§€ëŠ¥, ì¸ê°„ì§€ëŠ¥ì˜ í™•ì¥ - 3ë¶€-4ë¶€ - 5ë¶€ ì¸ê³µì§€ëŠ¥ì´ ì¸ê°„ì˜ ì¼ìë¦¬ë¥¼ ë¹¼ì•—ëŠ”ê°€? ì¸ê°„ì´ ì¸ê³µì§€ëŠ¥ì—ê²Œ ì¼ìë¦¬ ë¹¼ì•—ê¸¸ê¹Œ? ì¸ê³µì§€ëŠ¥ ì‹œëŒ€ì˜ ìƒˆë¡œìš´ ì¼ìë¦¬, 4ê°€ì§€\n",
      "\n",
      "í…ŒìŠ¤íŠ¸ 2: 'í•œêµ­ì˜ ì „í†µë¬¸í™”ëŠ”'\n",
      "ìƒì„± ê²°ê³¼: í•œêµ­ì˜ ì „í†µë¬¸í™”ëŠ” ìœ êµì˜ ì •ì‹ ë¬¸í™”ì´ë‹¤. ìœ êµëŠ” ëª¨ë“  ì‚¬ëŒì´ í‰ë“±í•˜ë‹¤ê³  ê°€ë¥´ì¹˜ê³  ìˆë‹¤â€ë©° â€œìš°ë¦¬ëŠ” ì´ëŸ¬í•œ ìœ êµë¥¼ ê³„ìŠ¹í•˜ê³  ë°œì „ì‹œì¼œ ë‚˜ê°€ì•¼ í•œë‹¤â€ê³  ê°•ì¡°í–ˆë‹¤(ã€í•œêµ­ìœ êµì˜ ì´í•´ã€, p.14). ê·¸ëŠ” ë˜ â€œìœ êµë„ ìœ êµì§€ë§Œ ìœ êµì—ì„œ ë§í•˜ëŠ”\n",
      "\n",
      "í…ŒìŠ¤íŠ¸ 3: 'ë”¥ëŸ¬ë‹ ê¸°ìˆ ì˜ ë¯¸ë˜ëŠ”'\n",
      "ìƒì„± ê²°ê³¼: ë”¥ëŸ¬ë‹ ê¸°ìˆ ì˜ ë¯¸ë˜ëŠ”?â€‹- AIëŠ” ì¸ê°„ì˜ í•™ìŠµëŠ¥ë ¥ê³¼ ì¶”ë¡ ëŠ¥ë ¥, ì§€ê°ëŠ¥ë ¥ì„ ê¸°ê³„ì  ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ êµ¬í˜„í•œ ê¸°ìˆ .- ì¸ê°„ì´ í•  ìˆ˜ ì—†ëŠ” ì¼ì„ AIê°€ ëŒ€ì‹ í•¨ìœ¼ë¡œì¨ ì¸ê°„ì€ ë” ë§ì€ ì‹œê°„ì„ ììœ ë¡­ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆê³ , ê·¸ë¡œ ì¸í•œ ê²½ì œì , ì‚¬íšŒì  ë°œì „\n",
      "\n",
      "==================================================\n",
      "ğŸ‰ í•œêµ­ì–´ ëª¨ë¸ íŒŒì¸íŠœë‹ ì™„ë£Œ!\n",
      "\n",
      "ë°°ìš´ ë‚´ìš©:\n",
      "1. DeepSpeed ì—†ì´ë„ íš¨ê³¼ì ì¸ íŒŒì¸íŠœë‹ ê°€ëŠ¥\n",
      "2. device_map ë¬¸ì œ í•´ê²° ë°©ë²•\n",
      "3. í•œêµ­ì–´ ëª¨ë¸ ì‚¬ìš©ë²•\n",
      "4. ì‹¤ìš©ì ì¸ í•™ìŠµ ì„¤ì •\n"
     ]
    }
   ],
   "source": [
    "# 6ë‹¨ê³„: í•™ìŠµëœ ëª¨ë¸ í…ŒìŠ¤íŠ¸\n",
    "print(\"í•™ìŠµëœ ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# í•œêµ­ì–´ í…ŒìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë“¤\n",
    "test_prompts = [\n",
    "    \"ì¸ê³µì§€ëŠ¥ì€\",\n",
    "    \"í•œêµ­ì˜ ì „í†µë¬¸í™”ëŠ”\",\n",
    "    \"ë”¥ëŸ¬ë‹ ê¸°ìˆ ì˜ ë¯¸ë˜ëŠ”\"\n",
    "]\n",
    "\n",
    "# ê° í”„ë¡¬í”„íŠ¸ì— ëŒ€í•´ í…ìŠ¤íŠ¸ ìƒì„±\n",
    "for i, prompt in enumerate(test_prompts, 1):\n",
    "    print(f\"\\ní…ŒìŠ¤íŠ¸ {i}: '{prompt}'\")\n",
    "    \n",
    "    try:\n",
    "        # ì…ë ¥ í† í°í™”\n",
    "        inputs = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            inputs = inputs.cuda()\n",
    "        \n",
    "        # í…ìŠ¤íŠ¸ ìƒì„±\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(\n",
    "                inputs,\n",
    "                max_length=70,\n",
    "                num_return_sequences=1,\n",
    "                temperature=0.7,\n",
    "                pad_token_id=tokenizer.eos_token_id,\n",
    "                do_sample=True,\n",
    "                top_p=0.9,\n",
    "                no_repeat_ngram_size=2\n",
    "            )\n",
    "        \n",
    "        # ìƒì„±ëœ í…ìŠ¤íŠ¸ ë””ì½”ë”©\n",
    "        generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        print(f\"ìƒì„± ê²°ê³¼: {generated_text}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ìƒì„± ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"ğŸ‰ í•œêµ­ì–´ ëª¨ë¸ íŒŒì¸íŠœë‹ ì™„ë£Œ!\")\n",
    "print(\"\\në°°ìš´ ë‚´ìš©:\")\n",
    "print(\"1. DeepSpeed ì—†ì´ë„ íš¨ê³¼ì ì¸ íŒŒì¸íŠœë‹ ê°€ëŠ¥\")\n",
    "print(\"2. device_map ë¬¸ì œ í•´ê²° ë°©ë²•\")\n",
    "print(\"3. í•œêµ­ì–´ ëª¨ë¸ ì‚¬ìš©ë²•\")\n",
    "print(\"4. ì‹¤ìš©ì ì¸ í•™ìŠµ ì„¤ì •\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed645229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í•™ìŠµëœ ëª¨ë¸ì„ ì €ì¥í•©ë‹ˆë‹¤...\n",
      "âœ… ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!\n",
      "ì €ì¥ ìœ„ì¹˜: ./finetuned_korean_model\n",
      "\n",
      "íŒŒì¸íŠœë‹ ì‹¤ìŠµì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ğŸ‰\n"
     ]
    }
   ],
   "source": [
    "# 7ë‹¨ê³„: ëª¨ë¸ ì €ì¥\n",
    "print(\"í•™ìŠµëœ ëª¨ë¸ì„ ì €ì¥í•©ë‹ˆë‹¤...\")\n",
    "\n",
    "try:\n",
    "    # ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ì €ì¥\n",
    "    model.save_pretrained(\"./finetuned_korean_model\")\n",
    "    tokenizer.save_pretrained(\"./finetuned_korean_model\")\n",
    "    \n",
    "    print(\"âœ… ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "    print(\"ì €ì¥ ìœ„ì¹˜: ./finetuned_korean_model\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ ëª¨ë¸ ì €ì¥ ì‹¤íŒ¨: {e}\")\n",
    "    \n",
    "print(\"\\níŒŒì¸íŠœë‹ ì‹¤ìŠµì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ğŸ‰\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
